## ğŸ”— Live Demo

ğŸ‘‰ https://simple-rag-app-5rbvxbvxhorgaj9uv2w2kj.streamlit.app/

# Simple RAG (Retrieval-Augmented Generation) Demo

This project is a **simple, end-to-end Retrieval-Augmented Generation (RAG) application** built to demonstrate how large language models can answer questions from custom documents.

The app allows users to **upload a PDF**, ask questions about its content, and receive answers generated using **retrieved document context**.

The project is intentionally kept **simple, lightweight, and free** so it can be easily deployed on **Streamlit Community Cloud** and explained clearly in interviews.

---

## ğŸš€ Features

- Upload any PDF document
- Automatic text chunking and embedding
- Semantic search using FAISS
- Context-aware answer generation
- No paid APIs
- CPU-only (cloud friendly)
- Deployed using Streamlit

---

## ğŸ§  How RAG Works in This Project

This project follows a **classic RAG pipeline**:

### 1ï¸âƒ£ Document Loading

- The uploaded PDF is loaded using `PyPDFLoader`.

### 2ï¸âƒ£ Text Splitting

- The document is split into small overlapping chunks using `RecursiveCharacterTextSplitter`.
- This improves retrieval accuracy.

### 3ï¸âƒ£ Embedding Generation

- Each chunk is converted into a vector embedding using:

### 4ï¸âƒ£ Vector Storage (FAISS)

- All embeddings are stored in a FAISS vector database for fast similarity search.

### 5ï¸âƒ£ Retrieval

- When a user asks a question, the most relevant document chunks are retrieved from FAISS.

### 6ï¸âƒ£ Answer Generation

- The retrieved context is combined with the userâ€™s question.
- A lightweight open-source language model (`google/flan-t5-small`) generates the final answer.

This approach ensures the model answers **based on the document**, not hallucinations.

---

## ğŸ—ï¸ Project Structure

### 4ï¸âƒ£ Vector Storage (FAISS)

- All embeddings are stored in a FAISS vector database for fast similarity search.

### 5ï¸âƒ£ Retrieval

- When a user asks a question, the most relevant document chunks are retrieved from FAISS.

### 6ï¸âƒ£ Answer Generation

- The retrieved context is combined with the userâ€™s question.
- A lightweight open-source language model (`google/flan-t5-small`) generates the final answer.

This approach ensures the model answers **based on the document**, not hallucinations.

## ğŸ–¥ï¸ Tech Stack

- **Python 3.10**
- **Streamlit** â€“ UI and hosting
- **LangChain (community modules)** â€“ document loading & embeddings
- **FAISS** â€“ vector database
- **Sentence Transformers** â€“ text embeddings
- **Hugging Face Transformers** â€“ lightweight open-source LLM
- **PyPDF** â€“ PDF parsing

---
